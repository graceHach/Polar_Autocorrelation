{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41571788-9859-48b5-8887-572670bc6050",
   "metadata": {},
   "source": [
    "# Polar Autocorrelation \n",
    "To run, make a folder and place in it data (xy coordinates, csv format, no header). Set the data_directory variable below to the name of the folder. Run all subsequent code blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dbaa08-f880-4a09-9642-faa0f8e895ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "data_directory = # Folder with data to be processed. All csvs in this folder will generate polar autocorrelation curves, but will not be overwritten.\n",
    "result_directory = current_directory # Folder where polar autocorrelation data will be placed. By default this is the current directory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b159cb4-3b70-4482-9921-279eb8b4fa23",
   "metadata": {},
   "source": [
    "# All function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd9252-921c-45fd-a14b-1dc2df711edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def autocorrelate(vector):\n",
    "    \"\"\"\n",
    "    Simple autocorrelation function, first point is self-comparison, and therefore equal to 1\n",
    "    Input:\n",
    "    vector - (int or floats) list-like collection of\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    denominator = 0\n",
    "    numerator = 0\n",
    "    n = len(vector)\n",
    "    mean = sum(vector)/n\n",
    "    result = [0]*n\n",
    "    for i in range(n):\n",
    "        denominator += (vector[i]-mean)**2\n",
    "    for k in range(n):\n",
    "        for i in range(n-k):\n",
    "            numerator += (vector[i]-mean)*(vector[i+k]-mean)\n",
    "        result[k] = numerator/denominator\n",
    "        numerator = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "def return_two_closest(point_,points_list):\n",
    "    \"\"\"\n",
    "    Returns two points closest to point_\n",
    "    Input:\n",
    "    point_ - list or tuple-like collection of two floats\n",
    "    points_list - list of similarly formatted points:\n",
    "    Output:\n",
    "    Closest point and second-closest point\n",
    "    \"\"\"\n",
    "    x, y = point_[0], point_[1]\n",
    "    # make list of distances between\n",
    "    distances = [((x-s[0])**2+(y-s[1])**2)**0.5 for s in points_list]\n",
    "    closest_index = distances.index(min(distances))\n",
    "    # Remove the element at the index containing the closest distance\n",
    "    del distances[closest_index]\n",
    "    second_closest_index = distances.index(min(distances))\n",
    "    point1 = points_list[closest_index]\n",
    "    point2 = points_list[second_closest_index]\n",
    "    return point1, point2\n",
    "\n",
    "\n",
    "def return_closest(point_, points_list):\n",
    "    \"\"\"\n",
    "    Returns point closest to point_\n",
    "    Input:\n",
    "    point_ - list or tuple-like collection of two floats\n",
    "    points_list - list of similarly formatted points:\n",
    "    Output:\n",
    "    Closest point\n",
    "    \"\"\"\n",
    "    x, y = point_[0], point_[1]\n",
    "    min_dist = min([((x-s[0])**2+(y-s[1])**2)**0.5 for s in points_list])\n",
    "    min_index = points_list.index([s for s in points_list if ((x-s[0])**2+(y-s[1])**2)**0.5 == min_dist][0])\n",
    "    point1 = points_list[min_index]\n",
    "    return point1\n",
    "\n",
    "\n",
    "def sort_CCW(points):\n",
    "    \"\"\"\n",
    "    Takes a pointcloud and sorts it in counterclockwise order, starting with a top point\n",
    "    Input: a list of points where each point is a tuple\n",
    "    Output: The same list of points, sorted in CCW order\n",
    "    \"\"\"\n",
    "    points_copy = points\n",
    "    x_only, y_only = [x for x, y in points], [y for x, y in points]\n",
    "    sorta = []\n",
    "    max_y = max(y_only)\n",
    "    # select point at top of point cloud\n",
    "    sorta.append([x for x in points if x[1] == max_y][0]) # add point with maximum y coordinate, as tuple, to sorta\n",
    "    points_copy.remove(sorta[0]) # remove max y point from points list\n",
    "    p1, p2 = return_two_closest(sorta[0], points_copy)\n",
    "    if p1[0]<p2[0]:   # if p1 is the leftmost point\n",
    "        sorta.append(p1) # add it to sorta\n",
    "        sorta.append(p2)\n",
    "    else:\n",
    "        sorta.append(p2)\n",
    "        sorta.append(p1)\n",
    "    points_copy.remove(p1)\n",
    "    points_copy.remove(p2)\n",
    "    # Iterate through each point\n",
    "    while len(points_copy) > 0:\n",
    "        p1 = return_closest(sorta[len(sorta)-1], points_copy)\n",
    "        sorta.append(p1)\n",
    "        points_copy.remove(p1)\n",
    "    return sorta\n",
    "\n",
    "\n",
    "def count_sign_changes(dataset):\n",
    "    \"\"\"\n",
    "    Counts the number of times a 1D list of numbers changes sign\n",
    "    Input: dataset, list of numbers\n",
    "    Output: # of sign changes of dataset\n",
    "    \"\"\"\n",
    "    sign_changes = 0\n",
    "    for i in range(len(dataset)-1):\n",
    "        if dataset[i]*dataset[i+1] <= 0:\n",
    "            sign_changes = sign_changes+1\n",
    "    return sign_changes\n",
    "\n",
    "\n",
    "def second_derivative_test(dataset):\n",
    "    \"\"\"\n",
    "    Number of times dataset changes concavity (second derivative changes sign)\n",
    "    Input: dataset, list of numbers\n",
    "    Output: number of sign changes of second derivative\n",
    "    \"\"\"\n",
    "    derivative = []\n",
    "    second_derivative = []\n",
    "    for i in range(len(dataset)-1):\n",
    "        dx = dataset[i+1]-dataset[i]\n",
    "        derivative.append(dx)\n",
    "    for i in range(len(derivative)-1):\n",
    "        d2x = derivative[i+1]-derivative[i]\n",
    "        second_derivative.append(d2x)\n",
    "    return count_sign_changes(second_derivative)\n",
    "\n",
    "def first_derivative_test(dataset):\n",
    "    \"\"\"\n",
    "    Number of times dataset changes concavity (second derivative changes sign)\n",
    "    Input: dataset, list of numbers\n",
    "    Output: number of sign changes of second derivative\n",
    "    \"\"\"\n",
    "    derivative = []\n",
    "    second_derivative = []\n",
    "    for i in range(len(dataset)-1):\n",
    "        dx = dataset[i+1]-dataset[i]\n",
    "        derivative.append(dx)\n",
    "    return count_sign_changes(derivative)\n",
    "\n",
    "\n",
    "def add_radial_distance(points_df):\n",
    "    \"\"\"\n",
    "    Returns a copy of points dataframe with radial distance column added\n",
    "    \"\"\"\n",
    "    points_df_copy = points_df\n",
    "    points_df_copy['r'] = 0\n",
    "    x_bar = sum(points_df['x'])/len(points_df['x'])\n",
    "    y_bar = sum(points_df['y'])/len(points_df['y'])\n",
    "    for i in range(len(points_df)):\n",
    "        points_df_copy.loc[i, 'r'] = ((points_df.loc[i, 'x'] - x_bar) ** 2 + (points_df.loc[i, 'y'] - y_bar) ** 2)**0.5\n",
    "    return points_df_copy\n",
    "\n",
    "\n",
    "def add_arc_length_parameterization(points_df):\n",
    "    \"\"\"\n",
    "    Returns a copy of points_df with arc length column added\n",
    "    \"\"\"\n",
    "    points_df_copy = points_df\n",
    "    points_df_copy['arc_length'] = 0\n",
    "    distance = 0\n",
    "    for i in range(len(points_df)-1):\n",
    "        distance += ((points_df.loc[i, 'x'] - points_df.loc[i+1, 'x'])**2 + (points_df.loc[i, 'y'] - points_df.loc[i+1, 'y'])**2)**0.5\n",
    "    cumulative_distance = 0\n",
    "    for i in range(len(points_df)-1):\n",
    "        cumulative_distance += ((points_df.loc[i, 'x'] - points_df.loc[i+1, 'x'])**2 + (points_df.loc[i, 'y']-points_df.loc[i+1, 'y'])**2)**0.5\n",
    "        points_df_copy.loc[i, 'arc_length'] = cumulative_distance/distance*360\n",
    "    return points_df_copy\n",
    "\n",
    "def arc_length_remapping(points_df):\n",
    "    \"\"\"\n",
    "    Takes the arc length column of points_df and returns a copy with it\n",
    "    remapped such that the angular zero is the maximum radial coordiante\n",
    "    \"\"\"\n",
    "    points_df_copy = points_df\n",
    "    points_r = list(points_df['r'])\n",
    "    points_arc = list(points_df['arc_length'])\n",
    "    max_r_index = points_r.index(max(points_r))\n",
    "    # slices and recombines radial and arc length coordinates\n",
    "    points_r = points_r[max_r_index:len(points_r)] + points_r[0:max_r_index]\n",
    "    points_arc = points_arc[max_r_index:len(points_r)] + points_arc[0:max_r_index]\n",
    "\n",
    "    # re-zeros the arc length coordinate such that first point (maximum r) is 0 degrees\n",
    "    new_arc = []\n",
    "    for i in points_arc:\n",
    "        if i >= points_arc[0]:\n",
    "            new_arc.append(i - points_arc[0])\n",
    "        else:\n",
    "            new_arc.append(i + 360 - points_arc[0])\n",
    "    points_df_copy['r'] = points_r\n",
    "    points_df_copy['arc_length'] = new_arc\n",
    "\n",
    "    return points_df_copy\n",
    "\n",
    "def get_csvs_from_directory(data_directory):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(data_directory, \"*.csv\"))  # What's the deal with OS module?\n",
    "    return csv_files\n",
    "\n",
    "def read_csv(csv_filename):\n",
    "    \"\"\"\n",
    "    Input: name of a csv file\n",
    "    Output: datafrane\n",
    "    \"\"\"\n",
    "    # add error handling for permission error\n",
    "    csv_df = pd.read_csv(csv_filename)\n",
    "    return csv_df\n",
    "\n",
    "def create_export_df(include_ac_curve, points_df):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    include_AC_curve - bool, if true includes autocorreation as a function of arc length displacement\n",
    "    points_df\n",
    "    Output: dataframe with autocorreation/feature detection results\n",
    "    \"\"\"\n",
    "    # Calculate autocorrelation and extract feature number\n",
    "    autocorrelation_vector = autocorrelate(points_df['r'])\n",
    "    # Feature extraction is int(# sign changes/2) or int(# sign changes of second derivative/2)\n",
    "    num_features_sign_change = count_sign_changes(autocorrelation_vector)//2\n",
    "    num_features_2nd_deriv = second_derivative_test(autocorrelation_vector)//2\n",
    "    if include_ac_curve:\n",
    "        result_df = pd.DataFrame(columns=['r_autocorreation', 'arc_length', 'num_features_sign_change', 'num_features_2nd_deriv', ])\n",
    "        result_df['arc_length'] = points_df['arc_length']\n",
    "        result_df['r_autocorreation'] = autocorrelation_vector\n",
    "    else:\n",
    "        result_df = pd.DataFrame(columns=['num_features_sign_change', 'num_features_2nd_deriv'])\n",
    "    result_df.loc[0, 'num_features_sign_change'] = num_features_sign_change\n",
    "    result_df.loc[0, 'num_features_2nd_deriv'] = num_features_2nd_deriv\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def export_df(result_df, data_filename):\n",
    "    result_df.to_csv(data_filename, index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d8e63-6bfe-4193-a23a-4e70d8d78bf9",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22835377-d08c-4401-b81e-95ad8668e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "def main():\n",
    "   \n",
    "    csvs_and_paths = get_csvs_from_directory(data_directory)\n",
    "    csv_file_names = [os.path.basename(file)[:-4] for file in csvs_and_paths]\n",
    "\n",
    "    # results appended to this in the same order as the filenames stored in data_csvs\n",
    "    results_dfs = []\n",
    "    # Iterate over each csv, creating dataframes with the results\n",
    "    for index, csv_file in enumerate(csvs_and_paths):\n",
    "        points_df = read_csv(csv_file)\n",
    "        if points_df.shape[1] == 2:\n",
    "            points_df.columns = ['x', 'y']\n",
    "            points_tuples = list(zip(points_df['x'], points_df['y']))\n",
    "            points_tuples_sorted = sort_CCW(points_tuples)\n",
    "            points_df['x'], points_df['y'] = [x for x, y in points_tuples_sorted], [y for x, y in points_tuples_sorted]\n",
    "            points_df = add_radial_distance(points_df)\n",
    "            points_df = add_arc_length_parameterization(points_df)\n",
    "            points_df = arc_length_remapping(points_df)\n",
    "            results_df = create_export_df(args.include_ac_curve, points_df)\n",
    "            results_dfs.append(results_df)\n",
    "            print(\"Processed \", csv_file_names[index])\n",
    "        else:\n",
    "            print(\"Data file should have two columns , corresponding to x and \"\n",
    "                  \"y coordinates. \",csv_file_names[index], \" has \",\n",
    "                  points_df.shape[1], \"columns.\")\n",
    "            csv_file_names.remove(csv_file_names[index])\n",
    "\n",
    "    # Export all csvs\n",
    "    os.chdir(result_directory)\n",
    "    for df, filename in zip(results_dfs, csv_file_names):\n",
    "        export_df(df, filename+\"_PolarAC.csv\")\n",
    "\n",
    "    print(\"Exported all processed files.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
